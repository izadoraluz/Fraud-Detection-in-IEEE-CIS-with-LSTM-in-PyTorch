# Credit Card Fraud Detection com LSTM (TensorFlow/Keras)

## **üë§ Integrante**

* [Izadora Luz](https://www.linkedin.com/in/izadoraluz-rsn/)

## **üë®‚Äçüè´ Professores**

* [Cesar Almi√±ana](https://www.linkedin.com/in/ccalminana/) ‚Äî Professor orientador
* [Crishna Irion](https://www.linkedin.com/in/crishna-irion-7b5aa311/) ‚Äî Professora de redes neurais


## **üìù Descri√ß√£o**

Este projeto implementa um pipeline completo para **detec√ß√£o de fraudes** em transa√ß√µes de cart√£o de cr√©dito usando **LSTM** (TensorFlow/Keras). O dataset √© o p√∫blico **Credit Card Fraud Detection (Kaggle ‚Äì MLG-ULB)**, com \~**284k** transa√ß√µes, sendo **492 fraudes** (‚âà **0,17%**).
O fluxo inclui: **EDA**, **preparo de dados** (normaliza√ß√£o, janelas temporais), **treinamento** de uma LSTM com **valida√ß√£o temporal**, **ajuste de limiar** por F1, e **avalia√ß√£o** com **Accuracy, Precision, Recall, F1 e AUC-ROC**, al√©m de curvas de aprendizado, ROC e matriz de confus√£o.

> ‚ö†Ô∏è Observa√ß√£o importante: como o dataset n√£o traz um ID de cliente/cart√£o, as sequ√™ncias foram criadas na **linha do tempo global**. Em cen√°rios reais, recomenda-se criar **sequ√™ncias por entidade** (cart√£o/cliente) e respeitar fronteiras por ID nos splits para liberar o real potencial das RNNs.

## **üéØ Objetivos**

1. Explorar e entender o dataset (distribui√ß√µes, correla√ß√µes, outliers).
2. Preparar dados para uma **rede LSTM** (normaliza√ß√£o e janelas temporais).
3. **Treinar** e **validar** o modelo com corte temporal.
4. **Avaliar** o desempenho e inspecionar **overfitting/underfitting** por curvas de aprendizado.
5. Documentar **decis√µes, limita√ß√µes** e **pr√≥ximos passos**.


## **‚öôÔ∏è Funcionalidades implementadas**

### **EDA**

* Checagem de nulos (nenhum encontrado).
* Estat√≠sticas descritivas e distribui√ß√£o de classes (forte desbalanceamento).
* Histogramas/boxplots de `Amount` (inclui `log1p`).
* Correla√ß√µes (ponto-biserial com `Class` + heatmap entre features PCA).

### **Preparo de dados**

* **Split temporal**: Train/Val/Test separados por tempo (evita vazamento futuro‚Üípassado).
* **StandardScaler** (fit no treino; aplica√ß√£o em val/test).
* **Sequ√™ncias deslizantes** com `LOOKBACK=10` passos.
* **Undersampling** leve no treino (\~10:1) + **class weights** para lidar com o desbalanceamento.

### **Modelo LSTM**

* Arquitetura enxuta (\~38k par√¢metros): `LSTM(64, return_sequences) ‚Üí BN ‚Üí Dropout ‚Üí LSTM(32) ‚Üí Dropout ‚Üí Dense(16) ‚Üí Sigmoid`.
* **Callbacks**: `EarlyStopping` (monitor AUC), `ReduceLROnPlateau`.
* Otimiza√ß√£o: `Adam` (lr inicial 1e-3).

### **Avalia√ß√£o**

* **M√©tricas**: Accuracy, Precision, Recall, F1, **AUC-ROC**.
* **Tuning de limiar** na valida√ß√£o para **F1**.
* **Curvas**: Loss/AUC (aprendizado), ROC (teste) e **Matriz de Confus√£o**.


## **üìÅ Estrutura de pastas**

```
.
‚îú‚îÄ‚îÄ fraud_lstm_pipeline.py        # script principal (EDA ‚Üí Preparo ‚Üí LSTM ‚Üí Avalia√ß√£o)
‚îú‚îÄ‚îÄ README.md
```


## **üíª Tecnologias Utilizadas**

* **Python 3.x**
* **TensorFlow/Keras** (LSTM, m√©tricas, callbacks)
* **Scikit-learn** (scalers, m√©tricas, pesos de classe)
* **Pandas & NumPy** (manipula√ß√£o de dados)
* **Matplotlib & Seaborn** (visualiza√ß√£o)


## **üöÄ Como rodar localmente**

1. Instale depend√™ncias (ideal usar venv/conda):

```bash
pip install numpy pandas matplotlib seaborn scikit-learn tensorflow
```

2. Execute:

```bash
python fraud_lstm_pipeline.py
```

3. Veja sa√≠das no terminal e gr√°ficos na pasta `figs/`.

> Dica: se dispon√≠vel, use GPU (TensorFlow com CUDA) para acelerar.


## **üß™ Experimentos e Resultados (resumo)**

**Distribui√ß√£o de classes (dados do projeto):**

* Negativa: **99,827%** (284.315)
* Positiva (fraude): **0,173%** (492)

**Valida√ß√£o (melhor √©poca):**

* **AUC(val)** ‚âà **0,588**
* `val_precision/val_recall` muito baixos com threshold 0,5 (classe rar√≠ssima).

**Threshold escolhido pela valida√ß√£o (max F1):**

* **0,40** (F1(val) ‚âà **0,007**)

**Teste (mantida distribui√ß√£o real):**

* **Accuracy:** 0,9926
* **Precision:** 0,0028
* **Recall:** 0,0133
* **F1:** 0,0047
* **AUC-ROC:** 0,5186

**Curvas/Gr√°ficos gerados:**

* `learning_curve_loss.png`, `learning_curve_auc.png`, `roc_curve_test.png`, `confusion_matrix_test.png` etc.


## **üîé Diagn√≥stico e Li√ß√µes**

* **Overfitting**: AUC treino (\~0,86) bem maior que AUC valida√ß√£o (\~0,59).
* **Sinal temporal fraco p/ LSTM**: sem ID de cart√£o/cliente, as janelas unem transa√ß√µes de entidades diferentes; a LSTM ‚Äúv√™‚Äù ru√≠do global.
* **Desbalanceamento extremo**: mesmo com undersampling no treino e class weights, **val/test** no desequil√≠brio real derrubam Precision/Recall; **AUC-PR** seria uma m√©trica ainda mais relevante.
* **M√©tricas com threshold fixo** no treino (0,5) pouco informativas; usar **PR-AUC**, **Recall\@K** e **threshold por custo** melhora a leitura.


## **üß≠ Pr√≥ximos passos**

1. **Sequ√™ncias por entidade** (cart√£o/cliente) com splits respeitando fronteiras por ID e tempo.
2. **Baseline tabular forte** (LogReg / XGBoost / LightGBM) com **features derivadas** (ex.: contagens/estat√≠sticas rolling por entidade, deltas de tempo, frequ√™ncia por merchant).
3. **Focal Loss** ou apenas **class weights** (sem undersampling agressivo) para melhorar **calibra√ß√£o**.
4. **M√©tricas e decis√£o orientadas a custo**: **PR-AUC**, **Recall\@K**, ajuste de **threshold** visando Recall/precision-alvo.
5. **Regulariza√ß√£o/arquitetura**: simplificar LSTM, ajustar Dropout/neur√¥nios; considerar **GRU/1D-CNN**.
6. **Calibra√ß√£o de probabilidades** (Platt/Isotonic) ap√≥s o treino.


## **‚öôÔ∏è Par√¢metros principais (no script)**

* `LOOKBACK=10` (tamanho da janela)
* `TEST_FRACTION=0.2` (corte temporal final para teste)
* `VAL_FRACTION=0.1` (parte final do treino para valida√ß√£o)
* `BATCH_SIZE=512`, `EPOCHS=30`, `LEARNING_RATE=1e-3`
* Undersampling no treino para \~**10:1** (neg\:pos) + `class_weight` balanceado
* EarlyStopping (monitor `val_auc`) e ReduceLROnPlateau
